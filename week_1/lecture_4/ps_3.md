# Problem set 3

## Gradient Descent


### Gradient Descent: Geometrically Revisited


Assume  ğœƒâˆˆâ„ . Our goal is to find  ğœƒ  that minimizes

ğ½(ğœƒ,ğœƒ0)=1ğ‘›âˆ‘ğ‘–=1ğ‘›Lossâ„(ğ‘¦(ğ‘–)(ğœƒâ‹…ğ‘¥(ğ‘–)+ğœƒ0))+ğœ†2âˆ£âˆ£ğœƒâˆ£âˆ£2 
 
through gradient descent. In other words, we will

Start  ğœƒ  at an arbitrary location:  ğœƒâ†ğœƒğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ 

Update  ğœƒ  repeatedly with  ğœƒâ†ğœƒâˆ’ğœ‚âˆ‚ğ½(ğœƒ,ğœƒ0)âˆ‚ğœƒ  until  ğœƒ  does not change significantly

In the 2 dimensional space below, we start our gradient descent at  ğœƒğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ . What is the direction  ğœƒ  moves to in its first update?


Answer = Towards the origin

What happens if we increase the stepsize  ğœ‚ ?

Answer = the magnitude of change in each update gets larger


Solution:

Gradient descent makes  ğœƒ  move to opposite direction of the gradient. Thus it will move towards the origin at  ğœƒğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ . Also, increasing the stepsize makes the update happen in greater magnitude.
