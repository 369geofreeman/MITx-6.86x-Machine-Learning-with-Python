# HomeWork 5

## Passive-aggressive algorithm


In this problem, we will try to understand the loss in Passive-Aggressive (PA) Perceptron algorithm.

The passive-aggressive (PA) algorithm (without offset) responds to a labeled training example  (ğ‘¥,ğ‘¦)  by finding  ğœƒ  that minimizes

 	 ğœ†2â€–â€–ğœƒâˆ’ğœƒ(ğ‘˜)â€–â€–2+Lossâ„(ğ‘¦ğœƒâ‹…ğ‘¥) 	 	(4.5)
where  ğœƒ(ğ‘˜)  is the current setting of the parameters prior to encountering  (ğ‘¥,ğ‘¦)  and

Lossâ„(ğ‘¦ğœƒâ‹…ğ‘¥)=max{0,1âˆ’ğ‘¦ğœƒâ‹…ğ‘¥} 
 
is the hinge loss. We could replace the loss function with something else (e.g., the zero-one loss). The form of the update is similar to the perceptron algorithm, i.e.,

 	 ğœƒ(ğ‘˜+1)=ğœƒ(ğ‘˜)+ğœ‚ğ‘¦ğ‘¥ 	 	(4.6)
but the real-valued step-size parameter  ğœ‚  is no longer equal to one; it now depends on both  ğœƒ(ğ‘˜)  and the training example  (ğ‘¥,ğ‘¦) .


### Update equation

Consider minimizing the above defined loss function with the hinge loss component.
What happens to the step size at large values of  ğœ† ? Please choose one from the options below:

Answer = If  ğœ†  is large, the step-size of the algorithm ( ğœ‚ ) would be small


### Calculating the Step size

Suppose  Lossâ„(ğ‘¦ğœƒ(ğ‘˜+1)â‹…ğ‘¥)>0  after the update. Express the value of  ğœ‚  in terms of  ğœ†  in this case. (Hint: you can simplify the loss function in this case).

Answer = 


### Loss functions and decision boundaries

Consider minimizing the above defined loss function and the setting of our decision boundary plotted below. We ran our PA algorithm on the next data point in our sequence - a positively-labeled vector (indicated with a  + ). We plotted the results of our algorithm after the update, by trying out a few different variations of loss function and  ğœ†  as follows:

hinge loss and a large  ğœ† 

hinge loss and a small  ğœ† 

0-1 loss and a large  ğœ† 

0-1 loss and a small  ğœ† 

Each of the options below provides a matching between the 4 variations above with a decision boundary plotted in a-d below. Please choose the options that match them correctly. Note that the dotted lines correspond to the previous decision boundary, and the solid blue lines correspond to the new decision boundary; also, note that these are just sketches which ignore any changes to the magnitude of  ğœƒ .

Answer:
* a = 
* b = 
* c = 
* d = 
