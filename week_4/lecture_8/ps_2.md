# Problem set two

### Neural Network Units


A neural network unit is a primitive neural network that consists of only the â€œinput layer", and an output layer with only one output. It is represented pictorially as follows:


A neural network unit computes a non-linear weighted combination of its input:

 	 ğ‘¦Ì‚  	 = 	 ğ‘“(ğ‘§)where ğ‘§=ğ‘¤0+âˆ‘ğ‘–=1ğ‘‘ğ‘¥ğ‘–ğ‘¤ğ‘– 	 	 
where  ğ‘¤ğ‘–  are numbers called weights ,  ğ‘§  is a number and is the weighted sum of the inputs  ğ‘¥ğ‘–,  and  ğ‘“  is generally a non-linear function called the activation function .

The above equation in vector form is:

 	 ğ‘¦Ì‚  	 = 	 ğ‘“(ğ‘§)where ğ‘§=ğ‘¤0+ğ‘¥â‹…ğ‘¤, 	 	 
where  ğ‘¥=[ğ‘¥1,â€¦,ğ‘¥ğ‘‘]  and  ğ‘¤=[ğ‘¤1,â€¦,ğ‘¤ğ‘‘]ğ‘‡ .


### Numerical Example - Neural Network Unit


In this problem, you will compute the output  ğ‘¦Ì‚ =ğ‘“(ğ‘§)  in the following neural network unit with 2 inputs  ğ‘¥1  and  ğ‘¥2 .


Let

 	 ğ‘¥ 	 = 	 [1,0] 	 	 
 	 ğ‘¤0 	 = 	 âˆ’3 	 	 
 	 ğ‘¤ 	 = 	 [1âˆ’1] 	 	 
First, compute  ğ‘§ .

Answer z = -2

The rectified linear function (ReLU) is defined as:

ğ‘“(ğ‘§)=max{0,ğ‘§}. 
 
Using the ReLU function as the activiation function  ğ‘“(ğ‘§) , compute  ğ‘¦Ì‚  :

Answer y = 0


### Hyperbolic Tangent Activation Function

In this problem, we will recall and refamiliarize ourselves with hyperbolic tangent function, which is commonly used as an activation function in a neural network.

Recall the hyperbolic tangent function is defined as

 	 tanh(ğ‘§) 	 = 	 ğ‘’ğ‘§âˆ’ğ‘’âˆ’ğ‘§ğ‘’ğ‘§+ğ‘’âˆ’ğ‘§=1âˆ’2ğ‘’2ğ‘§+1. 	 	 
What is the domain of  tanh(ğ‘§) , i.e. for what values of  ğ‘§  is  tanh(ğ‘§)  defined?


Answer = All real numbers

Find  tanh(0) . (Enter e for  ğ‘’ .)

Answer tanh(0) = 0

Is  tanh  odd, even, or neither?

Answer = odd

What is the range of  tanh ? Answer by giving the tightest lower bound, and a tightest upper bound of the set of all possible values of  tanh(ğ‘§) .

Answer = Lower bound -1
Answer = Upper bound = 1







