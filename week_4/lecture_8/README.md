# Lecture 8. Introduction to Feedforward Neural Networks


At the end of this lecture, you will be able to

Recognize different layers in a feedforward neural network and the number of units in each layer.

Write down common activation functions such as the hyperbolic tangent function  tanh , and the rectified linear function (ReLU) .

Compute the output of a simple neural network possibly with hidden layers given the weights and activation functions .

Determine whether data after transformation by some layers is linearly separable, draw decision boundaries given by the weight vectors and use them to help understand the behavior of the network.
