# Problem set 4


## Gating and LSTM


### Gating

Recall that the most simple, single-layered RNN can be written in equation as:

ğ‘ ğ‘¡=tanh(ğ‘Šğ‘ ,ğ‘ ğ‘ ğ‘¡âˆ’1+ğ‘Šğ‘ ,ğ‘¥ğ‘¥ğ‘¡). 
 
Recognize that, in the above formulation,  ğ‘ ğ‘¡  is always overwritten with the calculated result  tanh(ğ‘Šğ‘ ,ğ‘ ğ‘ ğ‘¡âˆ’1+ğ‘Šğ‘ ,ğ‘¥ğ‘¥ğ‘¡) .

Now, we introduce a gate vector  ğ‘”ğ‘¡  of the same dimension as  ğ‘ ğ‘¡ , which determines "how much information to overwrite in the next state." In equation, a single-layered gated RNN can be written as:

 	 ğ‘”ğ‘¡ 	 =sigmoid(ğ‘Šğ‘”,ğ‘ ğ‘ ğ‘¡âˆ’1+ğ‘Šğ‘”,ğ‘¥ğ‘¥ğ‘¡) 	 	 
 	 ğ‘ ğ‘¡ 	 =(1âˆ’ğ‘”ğ‘¡)â¨€ğ‘ ğ‘¡âˆ’1+ğ‘”ğ‘¡â¨€tanh(ğ‘Šğ‘ ,ğ‘ ğ‘ ğ‘¡âˆ’1+ğ‘Šğ‘ ,ğ‘¥ğ‘¥ğ‘¡). 	 	 
where the sign  â¨€  denotes element-wise multiplication. Now, which of the following is true about the gate  ğ‘”ğ‘¡ ?
(Choose all those apply.)

Answer = If the  ğ‘– th element of  ğ‘”ğ‘¡  is 0, the  ğ‘– th element of  ğ‘ ğ‘¡  and that of  ğ‘ ğ‘¡âˆ’1  are equal

Answer = If  ğ‘”ğ‘¡  is a vector whose elements are all 0,  ğ‘ ğ‘¡  and  ğ‘ ğ‘¡âˆ’1  are equal


### LSTM

Which of the following components of an LSTM represent the context or state? (Choose all that apply.)

Answer = ct

Answer = ht


### LSTM Calculations


Let all the neural network's weight matrices, the hidden state, and the memory cell be a scalar  1 . Let the new  ğ‘¥ -value be  5 . Calculate the value of the new hidden state. Round sigmoid to  1  or  0 , and round  tanh  to  âˆ’1  or  1 .


Answer = 1
