#Â problem set Two


## Why we need RNNs


### Video Quiz: Why We Need RNNs

As we saw in the previous problem, it is possible to use feed-forward networks for predicting future values of temporal sequences. However, there is a reason why recurrent neural networks can be more useful than feed-forward networks when it comes to temporal sequences. In general, RNNs automatically address some issues that need to be engineered with feed-forward networks. What are some of these issues?


Answer = How many time steps back should we look at in the feature vector?



### Understanding RNNs

You can use a vector representation of a sentence to...
(Choose all that apply.)


Answer = predict whether the sentence is positive or negative
Answer = translate the sentence to another language
Answer = to predict the next word in the sentence

All of the above tasks that you selected should use the same vector representation of the sentence.

Answer = False

In order to accomplish the tasks you selected above, which two steps are necessary?

Answer = mapping a sequence to a vector
Answer = mapping a vector to a prediction 


### Vector Representations

Only textual information, such as words and sentences, can be turned into vectors or matrices.

Answer = False
