# Homework Five


## Linear Regression and Regularization

In this question, we will investigate the fitting of linear regression.

### 5. (a)

For each of the datasets below, provide a simple feature mapping  ğœ™  such that the transformed data  (ğœ™(ğ‘¥(ğ‘–)),ğ‘¦(ğ‘–))  would be well modeled by linear regression.

Which feature mapping  ğœ™  is appropriate for the above model?

Answer = exp(ğ‘¥)

Which feature mapping  ğœ™  is appropriate for the above model?

Answer = ğœ™(ğ‘¥)=ğ‘¥âˆ’sign(ğ‘¥)

### 5. (b)


Consider fitting a  â„“2 -regularized linear regression model to data  (ğ‘¥(1),ğ‘¦(1)),â€¦,(ğ‘¥(ğ‘›),ğ‘¦(ğ‘›))  where  ğ‘¥(ğ‘¡),ğ‘¦(ğ‘¡)âˆˆâ„  are scalar values for each  ğ‘¡=1,â€¦,ğ‘› . To fit the parameters of this model, one solves

minğœƒâˆˆâ„, ğœƒ0âˆˆâ„ğ¿(ğœƒ,ğœƒ0) 
 
where

ğ¿(ğœƒ,ğœƒ0)=âˆ‘ğ‘¡=1ğ‘›(ğ‘¦(ğ‘¡)âˆ’ğœƒğ‘¥(ğ‘¡)âˆ’ğœƒ0)2  + ğœ†ğœƒ2 
 
Here  ğœ†â‰¥0  is a pre-specified fixed constant, so your solutions below should be expressed as functions of  ğœ†  and the data. This model is typically referred to as ridge regression .

Write down an expression for the gradient of the above objective function in terms of  ğœƒ .

Important: If needed, please enter  âˆ‘ğ‘›ğ‘¡=1(â€¦)  as a function sum_t(...), including the parentheses. Enter  ğ‘¥(ğ‘¡)  and  ğ‘¦(ğ‘¡)  as x^{t} and y^{t}, respectively.

Answer âˆ‚ğ¿âˆ‚ğœƒ=  -2*sum_t(x^{t})*(y^{t}-theta*x^{t}-theta_0)+2*lambda*theta


Write down an expression for the gradient of the above objective function in terms of  ğœƒ0 .

âˆ‚ğ¿âˆ‚ğœƒ0= -2*sum_t(y^{t}-theta*x^{t}-theta_0) 

