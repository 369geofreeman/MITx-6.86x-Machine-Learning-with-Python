#Â Homework One


## Collaborative Filtering, Kernels, Linear Regression


In this question, we will use the alternating projections algorithm for low-rank matrix factorization, which aims to minimize

ğ½(ğ‘ˆ,ğ‘‰)=12âˆ‘(ğ‘,ğ‘–)âˆˆğ·(ğ‘Œğ‘ğ‘–âˆ’[ğ‘ˆğ‘‰ğ‘‡]ğ‘ğ‘–)2î„½î„¾î…î…‹î…‹î…‹î…‹î…‹î…‹î…‹î…‹î…‹î…‹î…‹î…‹Squared Error+ğœ†2âˆ‘ğ‘=1ğ‘›âˆ‘ğ‘—=1ğ‘˜ğ‘ˆ2ğ‘ğ‘—+ğœ†2âˆ‘ğ‘–=1ğ‘šâˆ‘ğ‘—=1ğ‘˜ğ‘‰2ğ‘–ğ‘—î„½î„¾î…î…‹î…‹î…‹î…‹î…‹î…‹î…‹î…‹î…‹î…‹î…‹î…‹î…‹î…‹î…‹î…‹Regularization. 
 
In the following, we will call the first term the squared error term, and the two terms with  ğœ†  the regularization terms.

Let  ğ‘Œ  be defined as

ğ‘Œ=â¡â£â¢â¢â¢â¢5?4??2?37??6â¤â¦â¥â¥â¥â¥ 
 
ğ·  is defined as the set of indices  (ğ‘,ğ‘–) , where  ğ‘Œğ‘,ğ‘–  is not missing. In this problem, we let  ğ‘˜=ğœ†=1 . Additionally,  ğ‘ˆ  and  ğ‘‰  are initialized as  ğ‘ˆ(0)=[6,0,3,6]ğ‘‡ , and  ğ‘‰(0)=[4,2,1]ğ‘‡ .

### 1) a

Compute  ğ‘‹(0) , the matrix of predicted rankings  ğ‘ˆğ‘‰ğ‘‡  given the initial values for  ğ‘ˆ(0)  and  ğ‘‰(0) .

Answer = [[24, 12, 6], [0, 0, 0], [12, 6, 3], [24, 12, 6]]

### 2) b

Compute the squared error term, and the regularization terms in for the current estimate  ğ‘‹ .

Enter the squared error term (including the factor  1/2 ):

Answer = 511/2

Enter the regularization term (the sum of all the regularization terms):

Answer = 51

### 3) c

Suppose  ğ‘‰  is kept fixed. Run one step of the algorithm to find the new estimate  ğ‘ˆ(1) .

Enter the  ğ‘ˆ(1)  as a list of numbers,  [ğ‘ˆ(1)1,ğ‘ˆ(1)2,ğ‘ˆ(1)3,ğ‘ˆ(1)4] :

Answer = [27/18,4/5,16/17,12/6]
