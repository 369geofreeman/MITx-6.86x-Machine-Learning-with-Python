# Problem set 3

## Gradient Based Approach


### True or False

Let  ğ‘…ğ‘›(ğœƒ)  be the least squares criterion defined by

 	 ğ‘…ğ‘›(ğœƒ)=1ğ‘›âˆ‘ğ‘¡=1ğ‘›Loss(ğ‘¦(ğ‘¡)âˆ’ğœƒâ‹…ğ‘¥(ğ‘¡)). 	 
	 
Which of the following is true? Choose all those apply.

Answer = The least squares criterion  ğ‘…ğ‘›(ğœƒ)  is a sum of functions, one per data point.

Answer = âˆ‡ğœƒğ‘…ğ‘›(ğœƒ)  is a sum of functions, one per data point.

For every point, the loss is a function of  ğœƒ , so the least squares criterion  ğ‘…ğ‘›(ğœƒ)  is a sum of functions, one per data point, and this is what makes stochastic gradient descent possible. We want to do stochastic gradient descent because it is faster than gradient descent. Finally, because  ğ‘…ğ‘›(ğœƒ)  is sum of functions, one per data point,  âˆ‡ğœƒğ‘…ğ‘›(ğœƒ)  is also a sum of functions one per data point.
