# problem set five



## Regularization


### Regularization: extreme case 1

As in the video above, define the loss function

ğ½ğ‘›,ğœ†(ğœƒ,ğœƒ0)=1ğ‘›âˆ‘ğ‘¡=1ğ‘›(ğ‘¦(ğ‘¡)âˆ’ğœƒâ‹…ğ‘¥(ğ‘¡)âˆ’ğœƒ0)22+ğœ†2â€–ğœƒâ€–2 
 
where  ğœ†  is the regularization factor.


In the figure above, the blue dots are the training examples. If we increase  ğœ†  to  âˆ , where does  ğ‘“(ğ‘¥)=ğœƒâ‹…ğ‘¥+ğœƒ0  converge to?

Answer = Line 1

Solution:

If we increase  ğœ†  to  âˆ , minimizing  ğ½  is equivalent to minimizing  ||ğœƒ|| . Thus  ğœƒ  will have to be a zero vector. Thus  ğ‘“(ğ‘¥)=ğœƒâ‹…ğ‘¥+ğœƒ0  becomes  ğ‘“(ğ‘¥)=ğœƒ0 , a horizontal line. Thus  ğ‘“  converges to line 1.


### Regularization: Extreme case 2

As in the problem above,

ğ½ğ‘›,ğœ†(ğœƒ,ğœƒ0)=1ğ‘›âˆ‘ğ‘¡=1ğ‘›(ğ‘¦(ğ‘¡)âˆ’ğœƒâ‹…ğ‘¥(ğ‘¡)âˆ’ğœƒ0)22+ğœ†2â€–ğœƒâ€–2 
 
where  ğœ†  is the regularization factor.


In the figure above, the blue dots are the training examples. If we decrease  ğœ†  to  0 , where does  ğ‘“(ğ‘¥)=ğœƒâ‹…ğ‘¥+ğœƒ0  converge to?

Answer = Line 2


Solution:

If we decrease  ğœ†  to zero, minimizing  ğ½  is equivalent to minimizing  1ğ‘›âˆ‘ğ‘›ğ‘¡=1(ğ‘¦(ğ‘¡)âˆ’ğœƒâ‹…ğ‘¥(ğ‘¡)âˆ’ğœƒ0)22 , which is the "fit." Thus  ğ‘“  converges to line 2.
