#  Q value iteration by sampling


Let us consider a toy example which might not be very realistic but which neverthless can help delineate the Q-value iteration for RL using sampling approach.

For this example, assume that there are only two states,  ğ‘ 1,ğ‘ 2  and only one action possible from each of these states. Let  ğ‘ğ‘ 1 ,  ğ‘ğ‘ 2  be the actions that could be taken from  ğ‘ 1  and  ğ‘ 2  respectively.


The state transition probabilities are listed below and are also shown in the figure above.

 	 ğ‘‡(ğ‘ 1,ğ‘ğ‘ 1,ğ‘ 1)=0.1 	 	 
 	 ğ‘‡(ğ‘ 1,ğ‘ğ‘ 1,ğ‘ 2)=0.9 	 	 
 	 ğ‘‡(ğ‘ 2,ğ‘ğ‘ 2,ğ‘ 2)=0.1 	 	 
 	 ğ‘‡(ğ‘ 2,ğ‘ğ‘ 2,ğ‘ 1)=0.9 	 	 
The rewards for these actions are given by

 	 ğ‘…(ğ‘ 1,ğ‘ğ‘ 1,ğ‘ 1)=1 	 	 
 	 ğ‘…(ğ‘ 1,ğ‘ğ‘ 1,ğ‘ 2)=âˆ’1 	 	 
 	 ğ‘…(ğ‘ 2,ğ‘ğ‘ 2,ğ‘ 2)=âˆ’1 	 	 
 	 ğ‘…(ğ‘ 2,ğ‘ğ‘ 2,ğ‘ 1)=1 	 	 
Note that we resort to finding optimal  ğ‘„âˆ—  function by sampling for tasks where we don't have access to the exact  ğ‘‡,ğ‘…  functions. However, for this toy example we will assume that the Q-value iteration algorithm isn't directly provided with the above specified values of  ğ‘‡,ğ‘…  and has to resort to sampling to estimate the  ğ‘„  function.

Let's say that the agent starts out from state  ğ‘ 1  and collects few samples. Each sample can be described by the following tuple  (ğ‘ ,ğ‘,ğ‘ â€²,ğ‘…(ğ‘ ,ğ‘,ğ‘ â€²))  which indicates that the agent received a reward of  ğ‘…(ğ‘ ,ğ‘,ğ‘ â€²)  when it reached state  ğ‘ â€²  by taking action  ğ‘  from the state  ğ‘  .

The collected samples are described as follows in the order in which they are presented to the Q-value iteration algorithm.

 	 (ğ‘ 1,ğ‘ğ‘ 1,ğ‘ 1,+1) 	 	 
 	 (ğ‘ 1,ğ‘ğ‘ 1,ğ‘ 2,âˆ’1) 	 	 
 	 (ğ‘ 2,ğ‘ğ‘ 2,ğ‘ 1,+1) 	 	 
Let  ğ‘†ğ‘„(ğ‘ ,ğ‘)ğ‘˜  be used to denote the  ğ‘˜ğ‘¡â„  sample of  ğ‘„(ğ‘ ,ğ‘)  ( ğ‘˜=ğ‘–+1 ). Then recall that

ğ‘„Ì‚ ğ‘–+1(ğ‘ ,ğ‘)=ğ›¼ğ‘†ğ‘„(ğ‘ ,ğ‘)ğ‘˜+(1âˆ’ğ›¼)âˆ—ğ‘„Ì‚ ğ‘–(ğ‘ ,ğ‘) 
 
For all of the following problems, assume that the discount factor  ğ›¾=0.5 ,  ğ›¼=0.75  and that all the  ğ‘„  values are initialized to  0  to start with. That is,

ğ‘„Ì‚ 0(ğ‘ ,ğ‘)=0 for all ğ‘ ,ğ‘


## Numerical Example

Answer = Enter below the value of  ğ‘„(ğ‘ 1,ğ‘ğ‘ 1)  after the first sample is processed by the Q-value iteration algorithm







