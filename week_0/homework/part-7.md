#Â Homework


# Gradients and Optimization


## Multivariable Calculus Review: Simple Gradient

```
Let:

	ğ‘“: â„ğ‘‘ â†’ â„

	    â›ğœƒ1â
	ğœƒ = âœğœƒ2âœ â†¦ ğ‘“(ğœƒ)
	    âœ â‹®âœ
            âğœƒğ‘‘â  	 

denote a differentiable function. The gradient of  ğ‘“  is the vector-valued function


	 âˆ‡ğœƒğ‘“: â„ğ‘‘ â†’  â„ğ‘‘
	
	    â›ğœƒ1â      â›âˆ‚ğ‘“/âˆ‚ğœƒ1ââŸ
	ğœƒ = âœğœƒ2âœ â†¦    âœâˆ‚ğ‘“/âˆ‚ğœƒ2âœâŸ 
	    âœ â‹®âœ      âœ  â‹®   âœâŸ
            âğœƒğ‘‘â       ââˆ‚ğ‘“/âˆ‚ğœƒğ‘‘â âŸğœƒ 

Consider

	ğ‘“(ğœƒ)=ğœƒ21+ğœƒ22.

```

Compute the gradient  âˆ‡ğ‘“ .
(Enter your answer as a vector, e.g., type [2,x] for the vector  (2ğ‘¥) . Note the square brackets, and commas as separators. Enter theta_i for  ğœƒğ‘– . )

âˆ‡ğœƒğ‘“(ğœƒ) = 


<hr />

## Geometric Picture of the Function


As above, consider  ğ‘“(ğœƒ)=ğœƒ21+ğœƒ22 . Let us visualize  ğ‘“(ğœƒ)  as a surface on the  (ğœƒ1,ğœƒ2) -plane. We will use the usual horizonal plane as the  (ğœƒ1,ğœƒ2) -plane, and the vertical axis as the  ğ‘“(ğœƒ) -axis.

Consider the level curves  ğœƒ21+ğœƒ22=ğ¾  where  ğ¾>0  is some fixed real number.

What is the shapes of such a curve?

Answer = 


Consider how the level curves  ğœƒ21+ğœƒ22=+ğ¾  change as  ğ¾  increases from  0  to  âˆ . Does the graph (surface) of  ğ‘“(ğœƒ)  have a global maximum, or global minimum, or neither?

Answer = 


At each point  ğœƒ=(ğœƒ1,ğœƒ2)  in the  (ğœƒ1,ğœƒ2) -plane,  ğ‘“(ğœƒ)  decreases in the direction of...

Answer =  âˆ’âˆ‡ğœƒğ‘“(ğœƒ)

<hr />

Gradient ascent/descent methods are typical tools for maximizing/minimizing functions. Consider the function  ğ¿(ğ‘¥,ğœƒ)  where  ğœƒ=[ğœƒ1,ğœƒ2,â€¦,ğœƒğ‘›]ğ‘‡  and  ğ‘¥=[ğ‘¥1,ğ‘¥2,â€¦,ğ‘¥ğ‘›]ğ‘‡ . Our goal is to select  ğœƒ  such to maximize/minimize the value of  ğ¿  while keeping  ğ‘¥  fixed.

<hr />


## Compute the Gradient

```
The gradient  âˆ‡ğœƒğ¿(ğ‘¥,ğœƒ)  is a vector with  ğ‘›  components:


		    â›âˆ‚ / âˆ‚ğœƒ1 ğ¿(ğ‘¥,ğœƒ) â
	 âˆ‡ğœƒğ¿(ğ‘¥,ğœƒ) = âŸ       â‹®       âŸ.
		    ââˆ‚ / âˆ‚ğœƒğ‘› ğ¿(ğ‘¥,ğœƒ) â 


(Note that we are treating  ğ‘¥  as a constant and also differentiating w.r.t. to  ğœƒ .)

Let

	ğ¿(ğ‘¥,ğœƒ)=log(1+exp(âˆ’ğœƒâ‹…ğ‘¥)).

(Notice that here the  log  function is the natural algorithm.)
```

Evaluate the gradient  âˆ‡ğœƒğ¿(ğ‘¥,ğœƒ) . Which of the following is its  ğ‘—th  component?

Answer = 

<hr />

## Gradient Ascent or Descent

The direction of the derivative of a function gives us the direction of the largest change in the function as the independent variables vary.

In gradient ascent/descent methods, we make an educated guess about the next values of  ğœƒ , with consecutive updates that will hopefully eventually converge to the global minimum of  ğ¿(ğ‘¥,ğœƒ)  (if it exists).

```
If

	ğœƒâ€²=ğœƒ+ğœ–â‹…âˆ‡ğœƒğ¿(ğ‘¥,ğœƒ)
```
where  ğœ–  is a small positive real number, Which of the following is true?

Answer = ğ¿(ğ‘¥,ğœƒâ€²)>ğ¿(ğ‘¥,ğœƒ)













